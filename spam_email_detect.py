# -*- coding: utf-8 -*-
"""Fake_Email_Classification(Naive Baiyes-Modified).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TxgXG_UikcoHm57kNDmqWZZ9HGBr_wgQ
"""

!pip install scikit-learn pandas numpy

import os
import re
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix

from google.colab import drive
drive.mount('/content/drive')

# Step 1: Load emails
def load_emails(folder_path):
    emails = []
    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        with open(filepath, 'r', encoding='latin-1') as file:
            content = file.read()
            emails.append(content)
    return emails

# Step 2: Clean text
def clean_text(text):
    # Remove non-alphabetic characters and lowercase
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    return text.lower()

# Set paths
ham_path = '/content/drive/MyDrive/Data_sets/enron1/ham'
spam_path = '/content/drive/MyDrive/Data_sets/enron1/spam'

# Load and label data
ham_emails = load_emails(ham_path)
spam_emails = load_emails(spam_path)

emails = ham_emails + spam_emails
labels = [0] * len(ham_emails) + [1] * len(spam_emails)  # 0=ham, 1=spam

print("=== RAW HAM EMAIL EXAMPLE ===")
print(ham_emails[0][:50000])  # Show first 10000 characters of a ham email

print("\n=== RAW SPAM EMAIL EXAMPLE ===")
print(spam_emails[0][:10000])

# Clean emails
cleaned_emails = [clean_text(email) for email in emails]

print("\n=== CLEANED EMAIL EXAMPLE ===")
print(cleaned_emails[0])

# Step 3: Vectorize text using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)
X = vectorizer.fit_transform(cleaned_emails)
y = np.array(labels)

# Step 4: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Train Naive Bayes classifier
model = MultinomialNB()
model.fit(X_train, y_train)

# Step 6: Evaluate the model
y_pred = model.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=["Ham", "Spam"]))

import pickle

# Save the trained model and vectorizer
with open("spam_model.pkl", "wb") as f:
    pickle.dump((model, vectorizer), f)

print("âœ… Model and vectorizer saved as spam_model.pkl")

# Step 7: Manual Testing
while True:
    print("\nðŸ“§ Enter a custom email text (or type 'exit' to quit):")
    user_input = input("> ")

    if user_input.lower() == "exit":
        print("Goodbye!")
        break

    # Clean and transform the input
    cleaned_input = clean_text(user_input)
    input_vector = vectorizer.transform([cleaned_input])

    # Predict and show result
    prediction = model.predict(input_vector)[0]
    prob = model.predict_proba(input_vector)[0]

    print(f"\nPrediction: {'Spam' if prediction == 1 else 'Ham'}")
    print(f"Confidence: Spam {prob[1]*100:.2f}%, Ham {prob[0]*100:.2f}%")